{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passos para a realização da classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Carrega o arquivo fif(mne.Ep) dos dados filtrados;\n",
    "\n",
    "* Obter a \"energia\" do sinal por meio do cálculo compute_psd_;\n",
    "\n",
    "* Determine o limiar para isolar cada uma das frequências estimuladas. Por exemplo, a faixa de frequência para o estímulo de 6.5 Hz irá resultar em pontos (PSD) que irão variar de 6.3 à 6.7 Hz, caso o limiar seja de 0.2 Hz;\n",
    "\n",
    "* Com as listas de pontos isoladas para cada estimulo, aplique uma caraceristica adequada. Características manuais interessantes para este exemplo podem ser max_value, average ou median. No fim deste passo iremos obter um vetor de características;\n",
    "\n",
    "* Por fim, realize a classificação, que será um cálculo de voto simples (maior valor é provavelmente o da frequência evocada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 1, 15360) (4, 1, 21)\n",
      "\n",
      "Porcentagem de acerto: 85.71%\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "threshold = 0.25\n",
    "\n",
    "#load\n",
    "mne_data = [mne.read_epochs(\"../../../datasets/avi/single/filtered-sub-\" + str(i) + \".fif\", verbose=False) for i in range(4)]\n",
    "labels = np.load(\"../../../datasets/avi/single/labels.npy\")\n",
    "targets = [float(item) for item in mne_data[0].event_id.keys()]\n",
    "# print(mne_data[0].get_data().shape, labels.shape)\n",
    "\n",
    "# classificacao\n",
    "y_pred = []\n",
    "\n",
    "for subject in mne_data:\n",
    "    for i in range(len(subject)):\n",
    "        psd = subject[i].compute_psd(method='welch', fmin=5.5, fmax=10.5, verbose=False)\n",
    "        classes = [psd.get_data(fmin=freq-threshold, fmax=freq+threshold).max() for freq in targets]\n",
    "        y_pred.append( targets[ classes.index( max(classes) ) ])\n",
    "\n",
    "# acuracia\n",
    "y_test = labels.reshape(labels.shape[0] * labels.shape[1] * labels.shape[2])\n",
    "\n",
    "hits = [1 for i in range(len(y_test)) if y_pred[i] == y_test[i]]\n",
    "acc = 100 * sum(hits) / len(y_test)\n",
    "print(f'\\nPorcentagem de acerto: {acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# mne_d = mne.read_epochs(\"../../../datasets/avi/single/filtered-4-14-sub-0.fif\")\n",
    "# event_dict = {'6':0, '6.5':1, '7':2, '7.5':3, '8.2':4, '9.3':5, '10':6}\n",
    "\n",
    "values = {6: 6, 6.5: 6.5, 7: 7, 7.5: 7.5, 8.2: 8.2, 9.3: 9.3, 10: 10}\n",
    "\n",
    "labels_all = []\n",
    "freqs_all = []\n",
    "accs = []\n",
    "\n",
    "for i in range(5):\n",
    "    mne_d = mne.read_epochs(\"../../../datasets/avi/multi/filtered-4-14-sub-\" + str(i) + \".fif\", verbose=False)\n",
    "    labels = []\n",
    "    freqs = []\n",
    "\n",
    "    for i in range(len(mne_d)):\n",
    "        view = mne_d[i].compute_psd(method='multitaper', fmin=4, fmax=14, verbose=False)\n",
    "        df = view.to_data_frame()\n",
    "        freq = df['freq'][df['Oz'] == df['Oz'].max()].values[0]\n",
    "        closest_freq = min(values, key=lambda x: abs(x - freq))\n",
    "        freqs.append(closest_freq)\n",
    "        labels.append(float(df['condition'][0]))\n",
    "\n",
    "    labels_all.append(labels)\n",
    "    freqs_all.append(freqs)\n",
    "    accs.append(sum(np.array(freqs) == np.array(labels))/len(freqs))\n",
    "\n",
    "print(accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
